{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('Using GPU')\n",
    "  device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_datasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LongTestDataset, DAVISTestDataset, YouTubeVOSTestDataset\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmask_mapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaskMapper\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XMem\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'inference'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "from argparse import ArgumentParser\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from inference.data.test_datasets import LongTestDataset, DAVISTestDataset, YouTubeVOSTestDataset\n",
    "from inference.data.mask_mapper import MaskMapper\n",
    "from model.network import XMem\n",
    "from inference.inference_core import InferenceCore\n",
    "\n",
    "from progressbar import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# default configuration\n",
    "config = {\n",
    "    'top_k': 30,\n",
    "    'mem_every': 5,\n",
    "    'deep_update_every': -1,\n",
    "    'enable_long_term': True,\n",
    "    'enable_long_term_count_usage': True,\n",
    "    'num_prototypes': 128,\n",
    "    'min_mid_term_frames': 5,\n",
    "    'max_mid_term_frames': 10,\n",
    "    'max_long_term_elements': 10000,\n",
    "}\n",
    "\n",
    "network = XMem(config, './saves/XMem.pth').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_name = \"~/\"\n",
    "mask = np.array(Image.open(mask_name))\n",
    "print(np.unique(mask))\n",
    "num_objects = len(np.unique(mask)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from inference.interact.interactive_utils import image_to_torch, index_numpy_to_one_hot_torch, torch_prob_to_numpy_mask, overlay_davis\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "processor = InferenceCore(network, config=config)\n",
    "processor.set_all_labels(range(1, num_objects+1)) # consecutive labels\n",
    "cap = cv2.VideoCapture(video_name)\n",
    "\n",
    "# You can change these two numbers\n",
    "frames_to_propagate = 200\n",
    "visualize_every = 20\n",
    "\n",
    "current_frame_index = 0\n",
    "\n",
    "with torch.cuda.amp.autocast(enabled=True):\n",
    "  while (cap.isOpened()):\n",
    "    # load frame-by-frame\n",
    "    _, frame = cap.read()\n",
    "    if frame is None or current_frame_index > frames_to_propagate:\n",
    "      break\n",
    "\n",
    "    # convert numpy array to pytorch tensor format\n",
    "    frame_torch, _ = image_to_torch(frame, device=device)\n",
    "    if current_frame_index == 0:\n",
    "      # initialize with the mask\n",
    "      mask_torch = index_numpy_to_one_hot_torch(mask, num_objects+1).to(device)\n",
    "      # the background mask is not fed into the model\n",
    "      prediction = processor.step(frame_torch, mask_torch[1:])\n",
    "    else:\n",
    "      # propagate only\n",
    "      prediction = processor.step(frame_torch)\n",
    "\n",
    "    # argmax, convert to numpy\n",
    "    prediction = torch_prob_to_numpy_mask(prediction)\n",
    "\n",
    "    if current_frame_index % visualize_every == 0:\n",
    "      visualization = overlay_davis(frame, prediction)\n",
    "      display(Image.fromarray(visualization))\n",
    "\n",
    "    current_frame_index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
