import rclpy
from rclpy.node import Node
from rclpy.executors import MultiThreadedExecutor
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
from PIL import Image as PILImage
import requests
import torch
from transformers import OwlViTProcessor, OwlViTForObjectDetection
import time
from std_msgs.msg import String


class ImageSubscriber(Node):
    def __init__(self):
        super().__init__('image_subscriber')
        self.subscription = self.create_subscription(
            Image,
            '/camera/camera/color/image_raw',  # Change this to your image topic
            self.image_callback,
            10)
        self.subscription  # prevent unused variable warning
        self.bridge = CvBridge()
        self.pil_image = None

    def image_callback(self, msg):
        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        self.pil_image = PILImage.fromarray(cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB))
        cv2.imshow("Image Window", cv_image)
        cv2.waitKey(100)  # Wait for a key press for 1 millisecond

class TextSubscriber(Node):
    def __init__(self):
        super().__init__('text_subscriber')
        self.subscription = self.create_subscription(
            String,
            'text_topic',  # Change this to your image topic
            self.text_callback,
            10)
        self.subscription  # prevent unused variable warning
        self.text= None
        self.entering = False

    def text_callback(self, msg):
        self.text= msg.data
        self.entering = True
        print(self.text)


def main(args=None):
    rclpy.init(args=args)
    image_subscriber = ImageSubscriber()
    text_subscriber = TextSubscriber()

    processor = OwlViTProcessor.from_pretrained("google/owlvit-base-patch32")
    model = OwlViTForObjectDetection.from_pretrained("google/owlvit-base-patch32")

    executor = MultiThreadedExecutor()
    executor.add_node(image_subscriber)
    executor.add_node(text_subscriber)

    try:
        while rclpy.ok():
            executor.spin_once(timeout_sec=0.1)
            if text_subscriber.entering:
                text_subscriber.entering = False
                texts = [[text_subscriber.text]]
                image = image_subscriber.pil_image

                inputs = processor(text=texts,images=image,return_tensors="pt")
                outputs = model(**inputs)
                target_sizes = torch.tensor([image.size[::-1]])
                results=processor.post_process_object_detection(outputs, target_sizes=target_sizes,threshold=0.1)
                i = 0
                text = texts[i]
                boxes, scores, labels = results[i]["boxes"], results[i]["scores"], results[i]["labels"]
                for box, score, label in zip(boxes, scores, labels):
                     box = [round(i, 2) for i in box.tolist()]
                     print(f"Detected {text[label]} with confidence {round(score.item(), 3)} at location {box}")

                text_subscriber.entering = False

            time.sleep(0.1)
    except KeyboardInterrupt:
        pass
    finally:
        executor.remove_node(image_subscriber)
        executor.remove_node(text_subscriber)
        image_subscriber.destroy_node()
        text_subscriber.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()